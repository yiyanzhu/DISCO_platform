import base64
import os
import io
import time
import re
import pandas as pd
import dash
import dash_bootstrap_components as dbc
from dash import html, dcc, Input, Output, State, ctx, no_update, ALL, MATCH
from dash.exceptions import PreventUpdate
from pymatgen.core import Structure
import traceback
import sys
from pathlib import Path
import json

import crystal_toolkit.components as ctc
from crystal_toolkit.settings import SETTINGS

# è·¯å¾„è®¾ç½® (ç”¨äºå¯»æ‰¾ utils/SISSO_extract.py)
# å‡è®¾å½“å‰è„šæœ¬åœ¨ services/sisso/ æˆ–ç±»ä¼¼å­ç›®å½•ä¸‹ï¼ŒPROJECT_ROOT æŒ‡å‘é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# =============================================================================
# 1. SSH ç®¡ç†ç±» (çœŸå®é€»è¾‘)
# =============================================================================
from services.remote_server.ssh_manager import SSHManager as BaseSSHManager


class RealSSHManager:
    """Thin wrapper to reuse shared SSHManager while keeping existing interface."""

    def __init__(self, hostname, username, password, port=22, **kwargs):
        self._base = BaseSSHManager(hostname=hostname, port=int(port), username=username, password=password)

    def connect(self):
        ok, msg = self._base.connect()
        if ok:
            self._base.open_sftp()
        return ok, msg

    def mkdir_remote(self, dir_name):
        return self._base.mkdir_remote(dir_name)

    def write_remote_file(self, filename, content):
        if not isinstance(content, str):
            content = str(content)
        return self._base.write_remote_file(filename, content)

    def exec_command(self, command):
        ret, out, err = self._base.exec_command(command)
        return out, err

    def submit_job_slurm(self, dir_name):
        return self._base.submit_job_slurm(dir_name)

    def check_job_status(self, job_id):
        exists, _ = self._base.query_slurm_status(job_id)
        return "RUNNING" if exists else "COMPLETED"

    def list_remote_files(self, remote_dir):
        return self._base.list_remote_files(remote_dir)

    @property
    def sftp(self):
        return self._base.sftp

    def download_file(self, remote_path, local_path=None):
        success, content = self._base.read_remote_file(remote_path)
        if local_path and success:
            with open(local_path, "w", encoding="utf-8") as f:
                f.write(content)
            return True
        return content if success else None

    def close(self):
        self._base.close()

# =============================================================================
# 2. æ ¸å¿ƒé…ç½®ä¸ DataBuilder
# =============================================================================

CONFIG = {}
DEFAULT_CFG_PATH = Path(__file__).resolve().parent.parent / "services" / "config" / "default_config.json"
try:
    with open(DEFAULT_CFG_PATH, 'r', encoding='utf-8') as f:
        CONFIG = json.load(f)
except Exception:
    CONFIG = {
        "remote_server": {
            "hostname": "127.0.0.1", 
            "username": "user",          
            "password": "password",      
            "port": 22
        },
        "sisso_defaults": {"desc_dim": 2, "fcomplexity": 3}
    }

SSHManager = RealSSHManager

class SissoTrainDataBuilder:
    def __init__(self, df): 
        self.df = df
        
    def build_train_dat(self, structs, targets, indices, feats, parser): 
        lines = []
        prop_name = "Property"
        
        # ç‰¹å¾åˆ—è¡¨ï¼šå¦‚æœå¤–éƒ¨æœªä¼ å…¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
        feature_list = feats if feats and len(feats) > 0 else ["Radius", "Electronegativity"]
        
        # 1. ç”Ÿæˆè¡¨å¤´ (Header)
        # é€»è¾‘ï¼šéå†æ‰€æœ‰é€‰å®šçš„åŸå­ç´¢å¼• -> éå†æ‰€æœ‰ç‰¹å¾
        header_cols = [prop_name] 
        for idx in indices:
            for feat in feature_list:
                header_cols.append(f"Atom{idx}_{feat}")
                
        lines.append(" ".join(header_cols))
        
        # 2. ç”Ÿæˆæ•°æ®è¡Œ
        for s in structs:
            # [å…³é”®ä¿®å¤] å»é™¤åç¼€ (.cif, .vasp) ä»¥ä¾¿åŒ¹é… CSV ä¸­çš„ Key
            clean_name = os.path.splitext(s['filename'])[0]
            
            # ä» CSV å­—å…¸è·å–ç›®æ ‡å€¼
            val = targets.get(clean_name, 0.0)
            
            row = [str(val)] 
            
            # ç”Ÿæˆæ¨¡æ‹Ÿç‰¹å¾å€¼
            # ç¡®ä¿ç”Ÿæˆçš„åˆ—æ•°ä¸ header_cols é•¿åº¦ä¸€è‡´ (å‡å»Propertyåˆ—)
            base_seed = abs(hash(clean_name)) % 100
            total_cols = len(indices) * len(feature_list)
            
            for i in range(total_cols):
                mock_val = (base_seed / 10.0) + (i * 1.5)
                row.append(f"{mock_val:.3f}")
                
            lines.append(" ".join(row))
            
        return "\n".join(lines), len(structs), []

class SissoConfigManager: 
    def __init__(self, filepath): 
        self.filepath = filepath
        self.default_template = """ptype=1
ntask=1
scmt=.false.
desc_dim=2
nsample=298
restart=0
fstore=1
nsf= 15
ops='(+)(-)(*)(/)(^2)(sqrt)'
fcomplexity=5
fmax_min=1e-3
fmax_max=1e5
nf_sis=50000
method_so= 'L0'
fit_intercept=.false.
metric= 'RMSE'
nmodel=400
isconvex=(1,1,...)
bwidth=0.001
"""
        self.raw_content = self.default_template
        if self.filepath and os.path.exists(self.filepath):
            try:
                with open(self.filepath, 'r', encoding='utf-8') as f:
                    self.raw_content = f.read()
            except Exception as e:
                print(f"[Debug] è¯»å–å¤±è´¥: {e}")

    def update_template(self, params):
        content = self.raw_content
        if 'nsample' in params:
            content = re.sub(r"(nsample\s*=\s*)\d+", f"\\g<1>{params['nsample']}", content)
        if 'nsf' in params:
            content = re.sub(r"(nsf\s*=\s*)\d+", f"\\g<1>{params['nsf']}", content)
        if 'desc_dim' in params:
            content = re.sub(r"(desc_dim\s*=\s*)\d+", f"\\g<1>{params['desc_dim']}", content)
        if 'fcomplexity' in params:
            content = re.sub(r"(fcomplexity\s*=\s*)\d+", f"\\g<1>{params['fcomplexity']}", content)
        if 'ops' in params:
            content = re.sub(r"(ops\s*=\s*)'.*?'", f"ops='{params['ops']}'", content)
        return content

MAX_BATCHES = 12
ELEMENTS_DF = pd.DataFrame()
try:
    base_dir = os.path.dirname(os.path.abspath(__file__))
    search_paths = [os.path.join(base_dir, "elements_properties_all.csv")]
    found_path = next((p for p in search_paths if os.path.exists(p)), None)
    if found_path: ELEMENTS_DF = pd.read_csv(found_path)
except: pass

# =============================================================================
# 3. UI åˆå§‹åŒ–
# =============================================================================
app = dash.Dash(__name__, assets_folder=SETTINGS.ASSETS_PATH, external_stylesheets=[dbc.themes.BOOTSTRAP, "https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css"])
server = app.server

# å·¥å…·å‡½æ•°
def parse_structure(content_string: str, fmt: str = None) -> Structure:
    try:
        decoded = base64.b64decode(content_string)
        str_content = decoded.decode("utf-8")
        if fmt is None: fmt = "cif" if ("data_" in str_content[:500] or "_cell_" in str_content[:1000]) else "poscar"
        return Structure.from_str(str_content, fmt=fmt)
    except: return None

def parse_csv_content(content_string):
    if not content_string: return None, 0
    try:
        decoded = base64.b64decode(content_string.split(",")[1])
        df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
        df.iloc[:, 0] = df.iloc[:, 0].astype(str).str.strip()
        df.set_index(df.columns[0], inplace=True)
        return df, len(df)
    except: return None, 0

# UI ç»„ä»¶
new_batch_uploader = dcc.Upload(
    id="new-batch-uploader",
    children=html.Div([
        html.I(className="bi bi-cloud-upload", style={"fontSize": "2rem"}),
        html.Div("æ‹–å…¥æ–‡ä»¶ (.cif/.vasp)"),
        html.Div("ç”Ÿæˆæ–°æ‰¹æ¬¡", className="text-muted small")
    ]),
    className="upload-container",
    multiple=True
)

task_control_card = dbc.Card([
    dbc.CardHeader("3. ä»»åŠ¡æ§åˆ¶", className="bg-dark text-white py-2"),
    dbc.CardBody([
        dbc.Button("ç”Ÿæˆå¹¶åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡", id="btn-generate", color="primary", className="w-100 mb-2"),
        dbc.Button("é¢„è§ˆæ–‡ä»¶ / æäº¤", id="btn-open-editor", outline=True, color="info", className="w-100"),
        dbc.Button("æ‹‰å–çŠ¶æ€", id="btn-pull-status", outline=True, color="warning", className="w-100 mt-2"),
        html.Hr(className="my-2"),
        html.Div(id="log-gen", style={"height": "80px", "overflowY": "scroll", "backgroundColor": "#111", "color": "#0f0", "fontSize": "0.7rem", "whiteSpace": "pre-wrap", "padding": "5px"}),
        html.Div(id="log-sub", style={"height": "60px", "overflowY": "scroll", "backgroundColor": "#222", "color": "#0ff", "fontSize": "0.7rem", "whiteSpace": "pre-wrap", "padding": "5px"})
    ])
])

sisso_settings_card = dbc.Card([
    dbc.CardHeader("2. å…¨å±€å‚æ•°"),
    dbc.CardBody([
        dbc.Row([
            dbc.Col([
                dbc.Label("ç»´åº¦èŒƒå›´ (Min-Max)", className="small"),
                dbc.InputGroup([
                    dbc.Input(id="inp-dim-min", type="number", value=1, min=1, max=5, size="sm"),
                    dbc.InputGroupText("-", style={"padding": "0 5px"}),
                    dbc.Input(id="inp-dim-max", type="number", value=3, min=1, max=5, size="sm"),
                ], size="sm")
            ], width=6),
            dbc.Col([
                dbc.Label("å¤æ‚åº¦èŒƒå›´ (Min-Max)", className="small"),
                dbc.InputGroup([
                    dbc.Input(id="inp-cplx-min", type="number", value=2, min=1, max=10, size="sm"),
                    dbc.InputGroupText("-", style={"padding": "0 5px"}),
                    dbc.Input(id="inp-cplx-max", type="number", value=4, min=1, max=10, size="sm"),
                ], size="sm")
            ], width=6)
        ], className="mb-2"),
        dbc.Label("è¿ç®—ç¬¦", className="small"),
        dcc.Dropdown(id="inp-ops", options=[{'label': o, 'value': f'({o})'} for o in ['+', '-', '*', '/', 'exp', 'log', '^2', 'sqrt', 'sin', 'cos']], value=['(+)', '(-)', '(*)', '(/)'], multi=True, style={"fontSize": "0.8rem"}),
        html.Div([
            html.Hr(className="my-2"),
            dbc.Label("ç‰¹å¾å±æ€§", className="small"),
            dcc.Dropdown(id="feature-columns", options=[{'label': c, 'value': c} for c in ELEMENTS_DF.columns if c not in ['symbol', 'name', 'description']], multi=True, placeholder="ç•™ç©ºé»˜è®¤å…¨é€‰", style={"fontSize": "0.8rem"})
        ], id="feature-selection-container")
    ], style={"overflow": "visible"})
], style={"overflow": "visible", "zIndex": 100})

# æ–°å¢ï¼šç›´æ¥ä¸Šä¼ ç»„ä»¶
direct_train_uploader = dcc.Upload(
    id="direct-train-uploader",
    children=html.Div([
        html.I(className="bi bi-file-earmark-code", style={"fontSize": "2rem"}),
        html.Div("æ‹–å…¥ train.dat"),
        html.Div("ç›´æ¥ä½¿ç”¨ç°æœ‰æ•°æ®", className="text-muted small")
    ]),
    className="upload-container",
    multiple=False
)

file_editor_modal = dbc.Modal([
    dbc.ModalHeader(dbc.ModalTitle("é¢„è§ˆä¸ç¼–è¾‘")),
    dbc.ModalBody(dbc.Tabs([
        dbc.Tab(label="SISSO.in", children=[dcc.Textarea(id="editor-sisso", style={"width": "100%", "height": "400px", "fontFamily": "monospace"})]),
        dbc.Tab(label="train.dat", children=[dcc.Textarea(id="editor-train", style={"width": "100%", "height": "400px", "fontFamily": "monospace", "whiteSpace": "pre", "overflowX": "scroll"})])
    ])),
    dbc.ModalFooter([
        dbc.Button("å–æ¶ˆ", id="btn-close-modal", className="me-2"),
        dcc.Loading(dbc.Button("æäº¤ä»»åŠ¡", id="btn-submit-modal", color="primary"), type="circle")
    ])
], id="modal-file-editor", size="xl", backdrop=True, style={"zIndex": 10000}, is_open=False)

left_panel = [
    dbc.Card([
        dbc.CardHeader("1. æ–°å»º (New Batch)", className="bg-primary text-white py-2"),
        dbc.CardBody([
            dbc.RadioItems(
                id="tabs-input-mode",
                className="btn-group w-100 mb-3",
                inputClassName="btn-check",
                labelClassName="btn btn-outline-primary",
                labelCheckedClassName="active",
                options=[
                    {"label": "ä»ç»“æ„ç”Ÿæˆ", "value": "tab-struct"},
                    {"label": "ç›´æ¥ä¸Šä¼ ", "value": "tab-direct"},
                ],
                value="tab-struct",
            ),
            html.Div(new_batch_uploader, id="content-tab-struct"),
            html.Div([
                direct_train_uploader,
                html.Div(id="direct-upload-status", className="mt-2 text-success small")
            ], id="content-tab-direct", style={"display": "none"})
        ], className="p-2")
    ], className="mb-3"),
    html.Div(sisso_settings_card, className="mb-3"),
    html.Div(task_control_card, className="mb-3")
]
right_panel = [
    dbc.Card([dbc.CardHeader(["æ‰¹æ¬¡å·¥ä½œåŒº (Workspace)", dbc.Button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰", id="btn-reset-all", color="link", size="sm", className="float-end text-decoration-none text-danger py-0")], className="py-2"), 
              dbc.CardBody([html.Div(id="batches-container", className="row g-2"), html.Div("è¯·åœ¨å·¦ä¾§æ‹–å…¥ç»“æ„æ–‡ä»¶ä»¥å¼€å§‹...", id="empty-placeholder", className="text-center text-muted py-5")], className="p-2")], className="mb-3 h-100")
]

ctc.register_crystal_toolkit(app=app, layout=dbc.Container([
    file_editor_modal, 
    dcc.Store(id='store-batches-data', data=[], storage_type='local'), 
    dcc.Store(id='store-job-info', data={}, storage_type='local'), 
    dcc.Interval(id='interval-job-monitor', interval=10000, n_intervals=0),
    dbc.NavbarSimple(
        brand="ğŸ§¬ SISSO HPC Workflow",
        color="white", className="mb-3 shadow-sm",
        children=[dbc.NavItem(dbc.NavLink("Reset", href="/", external_link=True))]
    ), 
    dbc.Row([dbc.Col(left_panel, width=12, lg=3), dbc.Col(right_panel, width=12, lg=9)]),
    dbc.Row([dbc.Col(dbc.Card([dbc.CardHeader("4. è®¡ç®—ç»“æœ"), dbc.CardBody(html.Div(id='result-display'))], className="mt-3"), width=12)])
], fluid=True, style={"minHeight": "100vh", "backgroundColor": "#f8f9fa"}))

# =============================================================================
# 4. å›è°ƒå‡½æ•°
# =============================================================================

@app.callback(
    Output("store-batches-data", "data"), Output("batches-container", "children"), Output("empty-placeholder", "style"), Output("new-batch-uploader", "contents"),
    Input("new-batch-uploader", "contents"), Input("btn-reset-all", "n_clicks"),
    State("new-batch-uploader", "filename"), State("store-batches-data", "data"), State("batches-container", "children")
)
def create_new_batch(contents, n_reset, filenames, current_data, current_children):
    if ctx.triggered_id == "btn-reset-all": return [], [], {"display": "block"}, None
    if not contents: raise PreventUpdate
    if current_data is None: current_data = []
    if current_children is None: current_children = []
    
    new_structures = []
    for c, f in zip(contents, filenames):
        new_structures.append({'filename': f, 'content': c.split(",")[1]})
    
    batch_id = len(current_data)
    current_data.append({"id": batch_id, "structures": new_structures})
    
    init_struct = parse_structure(new_structures[0]['content']) if new_structures else None
    
    card = dbc.Col(dbc.Card([
        dbc.CardHeader([dbc.Row([
            dbc.Col([html.Strong(f"#{batch_id+1}"), html.Span(f"{len(new_structures)}", className="badge bg-secondary ms-1")], width="auto"),
            dbc.Col([dcc.Dropdown(id={'type': 'batch-struct-select', 'index': batch_id}, options=[{'label': s['filename'], 'value': i} for i, s in enumerate(new_structures)], value=0, clearable=False)], width=3),
            dbc.Col([dbc.Input(id={'type': 'batch-indices-input', 'index': batch_id}, placeholder="Index (e.g. 48 52)", size="sm")], width=4),
            dbc.Col([dcc.Upload(id={'type': 'batch-csv-upload', 'index': batch_id}, children=html.Div([html.Div([html.I(className="bi bi-file-earmark-arrow-up"), " CSV"], id={'type': 'batch-csv-label', 'index': batch_id}), html.Div(id={'type': 'batch-csv-status', 'index': batch_id}, className="text-success small fw-bold ms-1")]), style={"border": "1px dashed #6c757d", "height": "31px", "cursor": "pointer", "backgroundColor": "#f8f9fa", "display": "flex", "alignItems": "center", "justifyContent": "center"})], width=3)
        ], className="g-1 align-items-center")]),
        dbc.CardBody([ctc.StructureMoleculeComponent(init_struct, id=f"viewer-batch-{batch_id}", color_scheme="VESTA").layout(size="550px")])
    ], className="shadow-sm border-0 mb-3"), width=12, lg=6, xl=6)
    
    current_children.append(card)
    return current_data, current_children, {"display": "none"}, None

@app.callback([Output(f"viewer-batch-{i}", "data") for i in range(MAX_BATCHES)], Input({'type': 'batch-struct-select', 'index': ALL}, 'value'), State("store-batches-data", "data"))
def update_dynamic_viewers(vals, data):
    outs = [no_update] * MAX_BATCHES
    if not data or not vals: return outs
    for i, idx in enumerate(vals):
        if i < len(data) and idx is not None:
            outs[i] = parse_structure(data[i]['structures'][idx]['content'])
    return outs

@app.callback(Output({'type': 'batch-csv-status', 'index': MATCH}, 'children'), Output({'type': 'batch-csv-label', 'index': MATCH}, 'style'), Input({'type': 'batch-csv-upload', 'index': MATCH}, 'contents'), State({'type': 'batch-csv-upload', 'index': MATCH}, 'filename'))
def update_csv_status(c, f):
    if not c: return "", {"display": "block"}
    df, cnt = parse_csv_content(c)
    return f"âœ“ {f[:5]}..", {"display": "none"} if cnt > 0 else {"display": "block"}

# --- æ–°å¢ï¼šTab åˆ‡æ¢ä¸ç›´æ¥ä¸Šä¼ çŠ¶æ€ ---
@app.callback(
    Output("content-tab-struct", "style"), 
    Output("content-tab-direct", "style"),
    Output("feature-selection-container", "style"),
    Input("tabs-input-mode", "value")
)
def switch_tab_content(at):
    if at == "tab-direct":
        return {"display": "none"}, {"display": "block"}, {"display": "none"}
    return {"display": "block"}, {"display": "none"}, {"display": "block"}

@app.callback(Output("direct-upload-status", "children"), Input("direct-train-uploader", "contents"), State("direct-train-uploader", "filename"))
def update_direct_status(c, f):
    if c: return f"å·²åŠ è½½: {f}"
    return ""

# --- [æ ¸å¿ƒåˆå¹¶é€»è¾‘] åˆ—åæ ‡å‡†åŒ– ---
@app.callback(
    Output("log-gen", "children"),
    Output("editor-sisso", "value"),
    Output("editor-train", "value"),
    Input("btn-generate", "n_clicks"),
    State("store-batches-data", "data"),
    State({'type': 'batch-indices-input', 'index': ALL}, 'value'),
    State({'type': 'batch-csv-upload', 'index': ALL}, 'contents'),
    State("inp-dim-min", "value"),
    State("inp-dim-max", "value"),
    State("inp-cplx-min", "value"),
    State("inp-cplx-max", "value"),
    State("inp-ops", "value"),
    State("feature-columns", "value"),
    State("tabs-input-mode", "value"),
    State("direct-train-uploader", "contents")
)
def generate_merge(n, batch_data_list, indices_list, csv_contents_list, dim_min, dim_max, cplx_min, cplx_max, ops, feat_cols, active_tab, direct_content):
    if not n: raise PreventUpdate
    logs = ["å¼€å§‹å¤„ç†..."]
    
    # å ä½ç¬¦æ¨¡æ¿ç”Ÿæˆé€»è¾‘
    def get_sisso_template(nsample, nsf):
        try:
            cm = SissoConfigManager("services/sisso/templates/SISSO.in")
            # ä½¿ç”¨å ä½ç¬¦ {{dim}} å’Œ {{cplx}}
            return cm.update_template({
                "desc_dim": "{{dim}}",
                "nsample": nsample, 
                "nsf": nsf,
                "fcomplexity": "{{cplx}}",
                "ops": "".join(ops) if ops else ""
            })
        except Exception as e:
            return f"Template Error: {e}"

    # --- åˆ†æ”¯ 1: ç›´æ¥ä¸Šä¼ æ¨¡å¼ ---
    if active_tab == "tab-direct":
        if not direct_content:
            return "é”™è¯¯: è¯·å…ˆä¸Šä¼  train.dat æ–‡ä»¶", "", ""
        
        try:
            # è§£æ train.dat
            content_type, content_string = direct_content.split(',')
            decoded = base64.b64decode(content_string)
            final_train_dat = decoded.decode('utf-8')
            
            # ç®€å•è§£æä»¥è·å– nsample å’Œ nsf
            lines = final_train_dat.strip().split('\n')
            lines = [l for l in lines if l.strip()]
            
            if len(lines) < 2:
                return "é”™è¯¯: train.dat å†…å®¹è¿‡çŸ­", "", ""
                
            header = lines[0].split()
            real_nsample = len(lines) - 1
            # nsf = åˆ—æ•° - 2 (ç¬¬ä¸€åˆ—é€šå¸¸æ˜¯ Materials, ç¬¬äºŒåˆ—æ˜¯ Property)
            real_nsf = len(header) - 2
            
            logs.append(f"ã€ç›´æ¥æ¨¡å¼ã€‘å·²è§£æ train.dat: nsample={real_nsample}, nsf={real_nsf}")
            logs.append(f"ã€å‚æ•°èŒƒå›´ã€‘Dim: {dim_min}-{dim_max}, Cplx: {cplx_min}-{cplx_max}")
            
            sisso_in_content = get_sisso_template(real_nsample, real_nsf)
            return "\n".join(logs), sisso_in_content, final_train_dat
            
        except Exception as e:
            return f"è§£æ train.dat å¤±è´¥: {e}", "", ""

    # --- åˆ†æ”¯ 2: ç»“æ„ç”Ÿæˆæ¨¡å¼ ---
    if not batch_data_list: raise PreventUpdate
    
    current_feat_list = feat_cols if feat_cols and len(feat_cols) > 0 else ["Radius", "Electronegativity"]
    
    try:
        builder = SissoTrainDataBuilder(ELEMENTS_DF)
    except:
        builder = SissoTrainDataBuilder(ELEMENTS_DF)
        logs.append("[æ³¨æ„] ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨")

    all_dfs = []
    
    for i, batch_data in enumerate(batch_data_list):
        try:
            indices_str = str(indices_list[i]).replace(",", " ").strip()
            if not indices_str:
                logs.append(f"Batch #{i+1} è·³è¿‡: æœªè¾“å…¥åŸå­ç´¢å¼•")
                continue
            indices = [int(x) for x in indices_str.split()]
            
            csv_df, _ = parse_csv_content(csv_contents_list[i])
            if csv_df is None: 
                logs.append(f"Batch #{i+1} è·³è¿‡: æœªä¸Šä¼  CSV")
                continue
            
            targets_map = csv_df.iloc[:, 0].to_dict()
            valid_structs = [s for s in batch_data['structures'] if os.path.splitext(s['filename'])[0] in targets_map]
            
            if not valid_structs:
                logs.append(f"Batch #{i+1} è­¦å‘Š: æ— åŒ¹é…ç»“æ„")
                continue
            
            dat, _, _ = builder.build_train_dat(valid_structs, targets_map, indices, current_feat_list, parse_structure)
            df_base = pd.read_csv(io.StringIO(dat), sep='\s+')
            
            standard_names = []
            for idx_order in range(len(indices)): 
                for feat_name in current_feat_list:
                    standard_names.append(f"{idx_order + 1}_{feat_name}")
            
            current_cols = list(df_base.columns)
            if "Property" in current_cols:
                raw_feat_cols = [c for c in current_cols if c != "Property"]
                if len(raw_feat_cols) == len(standard_names):
                    rename_map = dict(zip(raw_feat_cols, standard_names))
                    df_base.rename(columns=rename_map, inplace=True)
            
            extra = csv_df.iloc[:, 1:]
            valid_ids = [os.path.splitext(s['filename'])[0] for s in valid_structs]
            if not extra.empty:
                df_base = pd.concat([df_base, extra.loc[valid_ids].reset_index(drop=True)], axis=1)
            
            df_base.insert(0, "materials", [f"b{i+1}_{mid}" for mid in valid_ids])
            all_dfs.append(df_base)
            
        except Exception as e:
            logs.append(f"Batch #{i+1} å¼‚å¸¸: {e}")

    if not all_dfs: return "\n".join(logs), "", ""

    final_df = pd.concat(all_dfs, ignore_index=True)
    if final_df.isnull().values.any():
        final_df.fillna(0, inplace=True)

    real_nsample = len(final_df)
    real_nsf = final_df.shape[1] - 2
    
    logs.append(f"ã€ç”ŸæˆæˆåŠŸã€‘nsample={real_nsample}, nsf={real_nsf}")
    logs.append(f"ã€å‚æ•°èŒƒå›´ã€‘Dim: {dim_min}-{dim_max}, Cplx: {cplx_min}-{cplx_max}")

    sisso_in_content = get_sisso_template(real_nsample, real_nsf)
    return "\n".join(logs), sisso_in_content, final_df.to_string(index=False)

@app.callback(Output("modal-file-editor", "is_open"), Input("btn-generate", "n_clicks"), Input("btn-open-editor", "n_clicks"), Input("btn-close-modal", "n_clicks"), Input("btn-submit-modal", "n_clicks"), State("modal-file-editor", "is_open"))
def toggle_modal(n1, n2, n3, n4, o):
    if ctx.triggered_id in ["btn-generate", "btn-open-editor"]: return True
    if ctx.triggered_id in ["btn-close-modal", "btn-submit-modal"]: return False
    return o

# --- [ä½œä¸šç®¡ç†] æäº¤ -> ç›‘æ§ -> æå– -> æ˜¾ç¤º ---
@app.callback(
    Output("store-job-info", "data"), Output("log-sub", "children"), Output("result-display", "children"),
    Input("btn-submit-modal", "n_clicks"), Input("interval-job-monitor", "n_intervals"), Input("btn-pull-status", "n_clicks"),
    State("editor-sisso", "value"), State("editor-train", "value"), State("store-job-info", "data"), State("log-sub", "children"),
    State("inp-dim-min", "value"), State("inp-dim-max", "value"), State("inp-cplx-min", "value"), State("inp-cplx-max", "value"),
    prevent_initial_call=True
)
def manage_job(n_submit, n_interval, n_pull, sisso_template, train, job_info, current_log, dim_min, dim_max, cplx_min, cplx_max):
    trigger = ctx.triggered_id
    
    # æäº¤ä½œä¸š
    if trigger == "btn-submit-modal":
        try:
            ssh = SSHManager(**CONFIG.get("remote_server", {}))
            ok, msg = ssh.connect()
            if not ok: return {}, f"è¿æ¥å¤±è´¥: {msg}", no_update
            
            # åˆ›å»ºä¸»ç›®å½•
            main_rd = f"SISSO_Batch_{int(time.time())}"
            ssh.mkdir_remote(main_rd)
            
            # ç¡®ä¿èŒƒå›´æœ‰æ•ˆ
            d_min = int(dim_min) if dim_min else 1
            d_max = int(dim_max) if dim_max else d_min
            c_min = int(cplx_min) if cplx_min else 1
            c_max = int(cplx_max) if cplx_max else c_min
            
            submitted_jobs = []
            logs = [f"åˆ›å»ºä¸»ç›®å½•: {main_rd}"]
            
            # éå†æ‰€æœ‰ç»„åˆ
            for d in range(d_min, d_max + 1):
                for c in range(c_min, c_max + 1):
                    sub_dir_name = f"d{d}_c{c}"
                    full_remote_path = f"{main_rd}/{sub_dir_name}"
                    
                    # 1. åˆ›å»ºå­ç›®å½•
                    ssh.mkdir_remote(full_remote_path)
                    
                    # 2. æ›¿æ¢æ¨¡æ¿å‚æ•°
                    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ sisso_template é‡Œæœ‰ {{dim}} å’Œ {{cplx}}
                    # å¦‚æœæ²¡æœ‰ï¼ˆæ¯”å¦‚ç”¨æˆ·æ‰‹åŠ¨æ”¹æ‰äº†ï¼‰ï¼Œreplace ä¸ä¼šç”Ÿæ•ˆï¼Œä¿æŒåŸæ ·
                    current_sisso = sisso_template.replace("{{dim}}", str(d)).replace("{{cplx}}", str(c))
                    
                    # 3. ä¸Šä¼ æ–‡ä»¶
                    ssh.write_remote_file(f"{full_remote_path}/SISSO.in", current_sisso)
                    ssh.write_remote_file(f"{full_remote_path}/train.dat", train)
                    
                    # 4. å¤åˆ¶å¹¶æäº¤è„šæœ¬
                    ssh.exec_command(f"cp ~/slurm.sh ~/{full_remote_path}/")
                    ok_sub, jid = ssh.submit_job_slurm(full_remote_path)
                    
                    if ok_sub:
                        submitted_jobs.append(jid)
                        logs.append(f"  [æäº¤] {sub_dir_name} -> JobID {jid}")
                    else:
                        logs.append(f"  [å¤±è´¥] {sub_dir_name} -> {jid}")
            
            ssh.close()
            
            if submitted_jobs:
                # ç­–ç•¥ï¼šåªç›‘æ§æœ€åä¸€ä¸ªæäº¤çš„ä»»åŠ¡ ID
                # è¿™æ ·å½“æœ€åä¸€ä¸ªä»»åŠ¡å®Œæˆæ—¶ï¼Œè§¦å‘æå–é€»è¾‘ï¼ˆè™½ç„¶æå–é€»è¾‘ç›®å‰å¯èƒ½åªä¼šå¤±è´¥æˆ–æå–éƒ¨åˆ†ï¼‰
                last_jid = submitted_jobs[-1]
                return {"remote_dir": main_rd, "job_id": last_jid, "status": "submitted", "all_jobs": submitted_jobs}, "\n".join(logs), no_update
            else:
                return {}, "\n".join(logs) + "\nå…¨éƒ¨æäº¤å¤±è´¥", no_update
                
        except Exception as e: return {}, f"å¼‚å¸¸: {e}", no_update

    # ç›‘æ§ä¸æå–
    elif trigger in ["interval-job-monitor", "btn-pull-status"]:
        if not job_info or job_info.get("status") != "submitted":
            if trigger == "btn-pull-status":
                return no_update, "æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡æˆ–ä»»åŠ¡ä¿¡æ¯å·²ä¸¢å¤±ï¼ˆè¯·é‡æ–°æäº¤ï¼‰", no_update
            raise PreventUpdate
        
        ssh = SSHManager(**CONFIG.get("remote_server", {}))
        ok, msg = ssh.connect()
        if not ok: return no_update, f"è¿æ¥ä¸­æ–­: {msg}", no_update
        
        # ç›‘æ§æœ€åä¸€ä¸ªä»»åŠ¡çš„çŠ¶æ€
        status = ssh.check_job_status(job_info["job_id"])
        
        if status == "RUNNING":
            ssh.close()
            base_log = current_log or ""
            # é¿å…æ—¥å¿—æ— é™å¢é•¿
            if "è¿è¡Œä¸­" not in base_log[-50:]:
                return no_update, f"{base_log}\n[è¿è¡Œä¸­] Job {job_info['job_id']} (åŠå…¶ä»–) is running...", no_update
            return no_update, no_update, no_update
            
        elif status == "COMPLETED":
            try:
                # >>> è‡ªåŠ¨æ‰§è¡Œæå–è„šæœ¬é€»è¾‘ >>>
                remote_dir = job_info['remote_dir']
                
                # --- æ­¥éª¤ A: åœ¨æ¯ä¸ªå­ç›®å½•è¿è¡Œ SISSO_extract.py ---
                # 1. å¯»æ‰¾æœ¬åœ° SISSO_extract.py
                extract_script_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "SISSO_extract.py")
                if not os.path.exists(extract_script_path):
                    # å¤‡ç”¨è·¯å¾„
                    extract_script_path = os.path.join(PROJECT_ROOT, "utils", "SISSO_extract.py")
                
                if os.path.exists(extract_script_path):
                    with open(extract_script_path, "r", encoding="utf-8") as f:
                        extract_content = f.read()
                    
                    # 2. ä¸Šä¼ æå–è„šæœ¬åˆ°ä¸»ç›®å½•
                    ssh.write_remote_file(f"{remote_dir}/SISSO_extract.py", extract_content)
                    
                    # 3. è·å–æ‰€æœ‰å­ç›®å½• (d*_c*)
                    # ä½¿ç”¨ find å‘½ä»¤æŸ¥æ‰¾å­ç›®å½•
                    cmd_find = f"find ~/{remote_dir} -maxdepth 1 -type d -name 'd*_c*'"
                    out_find, _ = ssh.exec_command(cmd_find)
                    subdirs = [p.strip() for p in out_find.split('\n') if p.strip()]
                    
                    # 4. éå†å­ç›®å½•å¹¶æ‰§è¡Œæå–
                    for subdir_path in subdirs:
                        subdir_name = os.path.basename(subdir_path)
                        # å¤åˆ¶è„šæœ¬åˆ°å­ç›®å½• -> æ‰§è¡Œ -> ç”Ÿæˆ results.csv
                        # æ³¨æ„: è¿™é‡Œçš„è·¯å¾„å¤„ç†è¦å°å¿ƒï¼Œsubdir_path æ˜¯ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„å–å†³äº find è¾“å‡º
                        # å‡è®¾ find è¾“å‡ºçš„æ˜¯ç»å¯¹è·¯å¾„ /home/user/.../d1_c2
                        
                        cmd_extract = (
                            f"cp ~/{remote_dir}/SISSO_extract.py {subdir_path}/ && "
                            f"cd {subdir_path} && "
                            f"python SISSO_extract.py"
                        )
                        ssh.exec_command(cmd_extract)
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°æå–è„šæœ¬ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­å°è¯•è¿è¡Œ draw.py (å¯èƒ½ç”¨æˆ·åªæƒ³ç”»å›¾?)
                    print(f"[Warning] æœ¬åœ°æœªæ‰¾åˆ° {extract_script_path}ï¼Œè·³è¿‡å­ç›®å½•æå–æ­¥éª¤ã€‚")

                # --- æ­¥éª¤ B: è¿è¡Œ draw.py æ±‡æ€»ç»˜å›¾ ---
                # 1. å¯»æ‰¾æœ¬åœ° draw.py è„šæœ¬
                draw_script_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "draw.py")
                if not os.path.exists(draw_script_path):
                    draw_script_path = os.path.join(PROJECT_ROOT, "utils", "draw.py")
                
                if os.path.exists(draw_script_path):
                    with open(draw_script_path, "r", encoding="utf-8") as f:
                        script_content = f.read()
                    
                    # 2. ä¸Šä¼ è„šæœ¬åˆ°ä¸»ç›®å½•
                    ssh.write_remote_file(f"{remote_dir}/draw.py", script_content)
                    
                    # 3. è¿œç¨‹æ‰§è¡Œ
                    cmd = f"cd ~/{remote_dir} && python draw.py"
                    ssh.exec_command(cmd)
                    
                    # 4. ä¸‹è½½ç»“æœæ–‡ä»¶
                    csv_content = ssh.download_file(f"{remote_dir}/all_models_rmse_complexity.csv")
                    
                    # å°è¯•ä¸‹è½½å›¾ç‰‡ (å‡è®¾æ˜¯ pareto_frontier.pngï¼Œå¦‚æœè„šæœ¬ç”Ÿæˆäº†å…¶ä»–åå­—ï¼Œè¿™é‡Œéœ€è¦è°ƒæ•´)
                    # å…ˆåˆ—å‡ºæ–‡ä»¶ç¡®è®¤å›¾ç‰‡å
                    ok_ls, files = ssh.list_remote_files(remote_dir)
                    img_filename = next((f for f in files if f.endswith(".png")), None)
                    img_base64 = None
                    
                    if img_filename:
                        # è¯»å–äºŒè¿›åˆ¶å›¾ç‰‡å†…å®¹
                        try:
                            with ssh.sftp.file(f"{remote_dir}/{img_filename}", "rb") as f:
                                img_bytes = f.read()
                                img_base64 = base64.b64encode(img_bytes).decode('utf-8')
                        except Exception as e:
                            print(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {e}")

                    ssh.close()
                    job_info["status"] = "finished"

                    # 5. ç»“æœå±•ç¤º
                    display_children = []
                    
                    # å¤„ç† CSV
                    if csv_content:
                        df_res = pd.read_csv(io.StringIO(csv_content))
                        # è½åœ°åˆ° outputs/discriptor
                        local_root = Path(CONFIG.get("local_paths", {}).get("results_root", "./outputs"))
                        out_dir = local_root / "discriptor"
                        out_dir.mkdir(parents=True, exist_ok=True)
                        df_res.to_csv(out_dir / "all_models_rmse_complexity.csv", index=False)
                        
                        # CSV ä¸‹è½½é“¾æ¥
                        csv_href = "data:text/csv;charset=utf-8," + base64.b64encode(csv_content.encode('utf-8')).decode('utf-8')
                        
                        display_children.append(html.H5("ğŸ“Š æè¿°ç¬¦ç»Ÿè®¡ç»“æœ"))
                        display_children.append(html.A(
                            dbc.Button("ğŸ“¥ ä¸‹è½½ CSV æ•°æ®", color="success", size="sm", className="mb-2"),
                            href=csv_href,
                            download="all_models_rmse_complexity.csv",
                            target="_blank"
                        ))
                        display_children.append(dbc.Table.from_dataframe(df_res, striped=True, bordered=True, hover=True, size="sm", style={"maxHeight": "300px", "overflowY": "scroll"}))
                        display_children.append(html.Hr())

                    # å¤„ç†å›¾ç‰‡
                    if img_base64:
                        img_src = f"data:image/png;base64,{img_base64}"
                        display_children.append(html.H5("ğŸ“ˆ å¸•ç´¯æ‰˜å‰æ²¿å›¾"))
                        display_children.append(html.A(
                            dbc.Button("ğŸ“¥ ä¸‹è½½å›¾ç‰‡", color="info", size="sm", className="mb-2"),
                            href=img_src,
                            download=img_filename,
                            target="_blank"
                        ))
                        display_children.append(html.Img(src=img_src, style={"maxWidth": "100%", "border": "1px solid #ddd", "padding": "5px"}))

                    if not display_children:
                        return job_info, "ä½œä¸šå®Œæˆï¼Œä½†æœªç”Ÿæˆæœ‰æ•ˆç»“æœæ–‡ä»¶ (CSV/PNG)", no_update
                        
                    return job_info, f"ä½œä¸šå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° {out_dir}", display_children
                else:
                    ssh.close()
                    return job_info, f"ä½œä¸šå®Œæˆï¼Œä½†åœ¨æœ¬åœ°æœªæ‰¾åˆ° {draw_script_path}ï¼Œæ— æ³•è‡ªåŠ¨æå–ã€‚", no_update
                # <<< ç»“æŸ >>>
                
            except Exception as e:
                ssh.close()
                return job_info, f"æå–è¿‡ç¨‹å‡ºé”™: {e}", no_update
        
        ssh.close()
    return no_update, no_update, no_update

if __name__ == "__main__":
    app.run(debug=True, port=8050)